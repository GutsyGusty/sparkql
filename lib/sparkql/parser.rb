#
# DO NOT MODIFY!!!!
# This file is automatically generated by Racc 1.4.8
# from Racc grammer file "".
#

require 'racc/parser.rb'

# $Id$
module Sparkql
  class Parser < Racc::Parser

module_eval(<<'...end sparkql.y/module_eval...', 'sparkql.y', 48)
  
  def parse(str)
    @lexer = Sparkql::Lexer.new(str)
    do_parse
  end

  def next_token
    t = @lexer.shift
	while t[0] == :SPACE or t[0] == :NEWLINE
	  t = @lexer.shift
	end
	t
  end
  
  def tokenize_expression(field, op, val)
    expression = {:field => field, :operator => op, :value => val, :conjunction => 'And' }
    puts "TOKEN: #{expression.inspect}"
    expression
  end

  def tokenize_conjunction(exp1, conj, exp2)
    exp2[:conjunction] = conj
    puts "tokenize_conjunction: #{conj.inspect}"
    [exp1, exp2]
  end
  
  def on_error(error_token_id, error_value, value_stack)
    puts "ERROR #{error_token_id} - #{error_value} - #{value_stack}"
    token_name = token_to_str(error_token_id)
    token_name.downcase!
    token = error_value.to_s.inspect
    str = 'parse error on '
    str << token_name << ' ' unless token_name == token
    str << token
    @lexer.error(str)
  end  

...end sparkql.y/module_eval...
##### State transition tables begin ###

racc_action_table = [
    20,    21,    22,    16,    18,    19,     2,     2,     5,     5,
    11,     9,    13,    14,     5,    12 ]

racc_action_check = [
    12,    12,    12,    12,    12,    12,     2,     0,     2,     0,
     4,     1,     9,    10,    11,     8 ]

racc_action_pointer = [
     2,    11,     1,   nil,     6,   nil,   nil,   nil,    12,    12,
     7,     7,    -8,   nil,   nil,   nil,   nil,   nil,   nil,   nil,
   nil,   nil,   nil,   nil ]

racc_action_default = [
    -2,   -17,   -17,    -1,    -3,    -9,    -4,    -5,   -17,   -17,
   -17,   -17,   -17,    24,    -8,    -7,   -14,   -10,   -15,   -16,
   -11,   -12,   -13,    -6 ]

racc_goto_table = [
     3,    15,    10,     1,    23,    17 ]

racc_goto_check = [
     2,     3,     2,     1,     7,     8 ]

racc_goto_pointer = [
   nil,     3,     0,   -10,   nil,   nil,   nil,    -8,    -7 ]

racc_goto_default = [
   nil,   nil,   nil,     4,     6,     7,     8,   nil,   nil ]

racc_reduce_table = [
  0, 0, :racc_error,
  1, 15, :_reduce_none,
  0, 15, :_reduce_2,
  1, 16, :_reduce_none,
  1, 16, :_reduce_none,
  1, 16, :_reduce_none,
  3, 17, :_reduce_6,
  3, 18, :_reduce_7,
  3, 19, :_reduce_none,
  1, 20, :_reduce_none,
  1, 21, :_reduce_none,
  1, 22, :_reduce_none,
  1, 22, :_reduce_none,
  1, 22, :_reduce_none,
  1, 22, :_reduce_none,
  1, 22, :_reduce_none,
  1, 22, :_reduce_none ]

racc_reduce_n = 17

racc_shift_n = 24

racc_token_table = {
  false => 0,
  :error => 1,
  :UMINUS => 2,
  :OPERATOR => 3,
  :CONJUNCTION => 4,
  "(" => 5,
  ")" => 6,
  :STANDARD_FIELD => 7,
  :INTEGER => 8,
  :DECIMAL => 9,
  :CHARACTER => 10,
  :DATE => 11,
  :DATETIME => 12,
  :BOOLEAN => 13 }

racc_nt_base = 14

racc_use_result_var = true

Racc_arg = [
  racc_action_table,
  racc_action_check,
  racc_action_default,
  racc_action_pointer,
  racc_goto_table,
  racc_goto_check,
  racc_goto_default,
  racc_goto_pointer,
  racc_nt_base,
  racc_reduce_table,
  racc_token_table,
  racc_shift_n,
  racc_reduce_n,
  racc_use_result_var ]

Racc_token_to_s_table = [
  "$end",
  "error",
  "UMINUS",
  "OPERATOR",
  "CONJUNCTION",
  "\"(\"",
  "\")\"",
  "STANDARD_FIELD",
  "INTEGER",
  "DECIMAL",
  "CHARACTER",
  "DATE",
  "DATETIME",
  "BOOLEAN",
  "$start",
  "target",
  "expressions",
  "expression",
  "conjunction",
  "group",
  "field",
  "condition",
  "literal" ]

Racc_debug_parser = false

##### State transition tables end #####

# reduce 0 omitted

# reduce 1 omitted

module_eval(<<'.,.,', 'sparkql.y', 11)
  def _reduce_2(val, _values, result)
     result = 0 
    result
  end
.,.,

# reduce 3 omitted

# reduce 4 omitted

# reduce 5 omitted

module_eval(<<'.,.,', 'sparkql.y', 21)
  def _reduce_6(val, _values, result)
     result = tokenize_expression(val[0], val[1],val[2]) 
    result
  end
.,.,

module_eval(<<'.,.,', 'sparkql.y', 25)
  def _reduce_7(val, _values, result)
     result = tokenize_conjunction(val[0], val[1],val[2]) 
    result
  end
.,.,

# reduce 8 omitted

# reduce 9 omitted

# reduce 10 omitted

# reduce 11 omitted

# reduce 12 omitted

# reduce 13 omitted

# reduce 14 omitted

# reduce 15 omitted

# reduce 16 omitted

def _reduce_none(val, _values, result)
  val[0]
end

  end   # class Parser
  end   # module Sparkql


# END PARSER
