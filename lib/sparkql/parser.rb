#
# DO NOT MODIFY!!!!
# This file is automatically generated by Racc 1.4.8
# from Racc grammer file "".
#

require 'racc/parser.rb'

# $Id$
module Sparkql
  class Parser < Racc::Parser

module_eval(<<'...end sparkql.y/module_eval...', 'sparkql.y', 56)
  
  def parse(str)
    @lexer = Sparkql::Lexer.new(str)
    do_parse
  end

  def next_token
    t = @lexer.shift
	while t[0] == :SPACE or t[0] == :NEWLINE
	  t = @lexer.shift
	end
	t
  end
  
  def tokenize_expression(field, op, val)
    expression = {:field => field, :operator => op, :value => val, :conjunction => 'And', :level => @lexer.level, :block_group => @lexer.block_group_identifier }
    puts "TOKEN: #{expression.inspect}"
    expression
  end

  def tokenize_conjunction(exp1, conj, exp2)
    exp2[:conjunction] = conj
    puts "tokenize_conjunction: #{conj.inspect}"
    [exp1, exp2]
  end
  
  def tokenize_group(expressions)
    puts "tokenize_group: #{expressions.inspect}"
    expressions
  end
  
  
  def on_error(error_token_id, error_value, value_stack)
    puts "ERROR #{error_token_id} - #{error_value} - #{value_stack}"
    token_name = token_to_str(error_token_id)
    token_name.downcase!
    token = error_value.to_s.inspect
    str = 'parse error on '
    str << token_name << ' ' unless token_name == token
    str << token
    @lexer.error(str)
  end  

...end sparkql.y/module_eval...
##### State transition tables begin ###

racc_action_table = [
    20,    21,    23,    16,    18,    19,     2,     2,     5,     5,
    11,     2,    14,     5,    13,    11,     9,    12 ]

racc_action_check = [
    12,    12,    12,    12,    12,    12,    11,     2,    11,     2,
    10,     0,    10,     0,     9,     3,     1,     7 ]

racc_action_pointer = [
     6,    16,     2,    11,   nil,   nil,   nil,    14,   nil,    14,
     6,     1,    -8,   nil,   nil,   nil,   nil,   nil,   nil,   nil,
   nil,   nil,   nil,   nil ]

racc_action_default = [
    -2,   -17,   -17,    -1,    -3,    -9,    -4,   -17,    -6,   -17,
   -17,   -17,   -17,    24,    -8,    -7,   -14,   -10,   -15,   -16,
   -11,   -12,    -5,   -13 ]

racc_goto_table = [
     3,    15,    10,     1,    22,    17 ]

racc_goto_check = [
     2,     3,     2,     1,     6,     8 ]

racc_goto_pointer = [
   nil,     3,     0,   -10,   nil,   nil,    -8,   nil,    -7 ]

racc_goto_default = [
   nil,   nil,   nil,     4,     6,     7,   nil,     8,   nil ]

racc_reduce_table = [
  0, 0, :racc_error,
  1, 15, :_reduce_none,
  0, 15, :_reduce_2,
  1, 16, :_reduce_none,
  1, 16, :_reduce_none,
  3, 17, :_reduce_5,
  1, 17, :_reduce_none,
  3, 18, :_reduce_7,
  3, 21, :_reduce_8,
  1, 19, :_reduce_none,
  1, 20, :_reduce_none,
  1, 22, :_reduce_none,
  1, 22, :_reduce_none,
  1, 22, :_reduce_none,
  1, 22, :_reduce_none,
  1, 22, :_reduce_none,
  1, 22, :_reduce_none ]

racc_reduce_n = 17

racc_shift_n = 24

racc_token_table = {
  false => 0,
  :error => 1,
  :UMINUS => 2,
  :OPERATOR => 3,
  :CONJUNCTION => 4,
  :LPAREN => 5,
  :RPAREN => 6,
  :STANDARD_FIELD => 7,
  :INTEGER => 8,
  :DECIMAL => 9,
  :CHARACTER => 10,
  :DATE => 11,
  :DATETIME => 12,
  :BOOLEAN => 13 }

racc_nt_base = 14

racc_use_result_var = true

Racc_arg = [
  racc_action_table,
  racc_action_check,
  racc_action_default,
  racc_action_pointer,
  racc_goto_table,
  racc_goto_check,
  racc_goto_default,
  racc_goto_pointer,
  racc_nt_base,
  racc_reduce_table,
  racc_token_table,
  racc_shift_n,
  racc_reduce_n,
  racc_use_result_var ]

Racc_token_to_s_table = [
  "$end",
  "error",
  "UMINUS",
  "OPERATOR",
  "CONJUNCTION",
  "LPAREN",
  "RPAREN",
  "STANDARD_FIELD",
  "INTEGER",
  "DECIMAL",
  "CHARACTER",
  "DATE",
  "DATETIME",
  "BOOLEAN",
  "$start",
  "target",
  "expressions",
  "expression",
  "conjunction",
  "field",
  "condition",
  "group",
  "literal" ]

Racc_debug_parser = false

##### State transition tables end #####

# reduce 0 omitted

# reduce 1 omitted

module_eval(<<'.,.,', 'sparkql.y', 11)
  def _reduce_2(val, _values, result)
     result = 0 
    result
  end
.,.,

# reduce 3 omitted

# reduce 4 omitted

module_eval(<<'.,.,', 'sparkql.y', 20)
  def _reduce_5(val, _values, result)
     result = tokenize_expression(val[0], val[1],val[2]) 
    result
  end
.,.,

# reduce 6 omitted

module_eval(<<'.,.,', 'sparkql.y', 26)
  def _reduce_7(val, _values, result)
     result = tokenize_conjunction(val[0], val[1],val[2]) 
    result
  end
.,.,

module_eval(<<'.,.,', 'sparkql.y', 30)
  def _reduce_8(val, _values, result)
     result = tokenize_group(val[1]) 
    result
  end
.,.,

# reduce 9 omitted

# reduce 10 omitted

# reduce 11 omitted

# reduce 12 omitted

# reduce 13 omitted

# reduce 14 omitted

# reduce 15 omitted

# reduce 16 omitted

def _reduce_none(val, _values, result)
  val[0]
end

  end   # class Parser
  end   # module Sparkql


# END PARSER
